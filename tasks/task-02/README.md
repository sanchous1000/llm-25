# Лаба 2 — Построение RAG-агента по документации

## Что нужно сделать

### 1) Выбрать и подготовить источники данных

Выберите корпус документов, на основе которого будет работать RAG-агент.

- Примеры: корпоративные регламенты, презентации, учебные материалы, база знаний, репозитории.
- Объем: не менее 50 страниц суммарного текста.
- Подготовьте 10–20 репрезентативных вопросов пользователей по вашим документам.

---

### 2) Спарсить источники в Markdown

Реализуйте конвертацию исходных форматов в нормализованный Markdown со структурой и метаданными.

- Форматы: DOCX, PPTX, PDF, HTML/MD (в зависимости от корпуса).
- Нормализация: корректные заголовки/списки/таблицы, сохранение структуры разделов (если позволяет корпус), метаданные (источник, раздел/страница/слайд, путь, дата).



---

### 3) Разбить на чанки и построить эмбеддинги (sparse/dense)

Спроектируйте стратегию разбиения и векторизации.

- Разбиение по вашему усмотрению: рекурсивный сплиттер с учетом заголовков; markdown-сплиттер по h1–h3; гибрид (заголовки + окно/overlap).
- Параметры подбора: размер чанка 100–1 000 токенов, overlap на ваше усмотрение, включение заголовков в текст чанка/метаданные.
- Эмбеддинги: dense (например, e5-large-v2, bge-base/bge-m3, OpenAI text-embedding-3-large и аналоги) или sparse (BM25, SPLADE); допустим гибрид.

- Параметры должны быть конфигурируемыми (CLI/конфиг/.env): тип сплиттера, `chunk_size`, `overlap`, включение заголовков, модель эмбеддингов, тип векторизации (dense/sparse/hybrid).
- Скрипт должен поддерживать повторный запуск без ручной очистки: переcборка чанков и эмбеддингов при изменении параметров; артефакты версионируйте через метаданные/пути.
- Эти параметры будут меняться на шаге 5 для улучшения метрик — обеспечьте удобное изменение через флаги/конфигурацию.


Артефакты: скрипт построения чанков/эмбеддингов (например, `scripts/build_index.py`).

---

### 4) Развернуть векторное хранилище и загрузить индекс

Выберите решение для векторного пространства и загрузите коллекцию.

- Варианты: Qdrant (локально/облако), Faiss (локально), Elasticsearch/OpenSearch (гибридный поиск).
- Схема: на ваше усмотрение.
- Индекс: HNSW-параметры (`M`, `ef_construction`, `ef_search`), опционально квантование/компрессия.
- Результат: коллекция создана, эмбеддинги загружены (скрипт — `scripts/load_to_vector_store.py`).

- Модуль должен быть доступен для пересборки/переиндексации при изменении параметров из п.3 (например, флаги `--rebuild`, `--drop-and-reindex`).
- Обеспечьте идемпотентность: повторный запуск не должен ломать состояние; предусмотрите быстрый reset коллекции.

---

### 5) Метрики и оценка качества retrieval/QA

После построения индекса и загрузки эмбеддингов измерьте качество извлечения и ответа.

- Набор оценочных запросов: используйте 10–20 вопросов из п.1 с эталонными релевантными документами/чанками.
- Retrieval-метрики: Recall@k, Precision@k, MRR, (зафиксируйте k, например, 5 и 10).
- Зафиксируйте конфигурацию из п.3–4 (параметры сплиттера, эмбеддингов, индекса) и сравните минимум 2–3 варианта.
- Сделайте выводы и отметьте конфигурацию с лучшими метриками/затратами.

---

### 6) Реализовать движок общения (RAG-пайплайн)

Сервис должен принимать вопрос пользователя, искать релевантные чанки и формировать ответ LLM с цитатами.

*Этапы*: 
1. векторизация запроса, 
2. поиск, 
3. сборка промпта (инструкции+вопрос+топ-N контекстов), 
4. вызов LLM из Лабораторной работы 1, 
5. ответ с цитатами (источник, страница/слайд, сниппет).


