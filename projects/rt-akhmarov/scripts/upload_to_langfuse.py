import json
import os
import argparse
from langfuse import Langfuse
from langfuse.model import CreateDatasetItemRequest
from dotenv import load_dotenv

load_dotenv()

def load_jsonl(file_path):
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                data.append(json.loads(line))
    return data

def main():
    parser = argparse.ArgumentParser(description="–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ Langfuse")
    parser.add_argument("--file", default="data/verl_questions.jsonl", help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏")
    parser.add_argument("--dataset_name", default="verl_lab_dataset", help="–ò–º—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ Langfuse")
    parser.add_argument("--input_key", default="question", help="–ö–ª—é—á JSON, –≥–¥–µ –ª–µ–∂–∏—Ç –≤–æ–ø—Ä–æ—Å")
    parser.add_argument("--output_key", default="answer", help="–ö–ª—é—á JSON, –≥–¥–µ –ª–µ–∂–∏—Ç —ç—Ç–∞–ª–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç")
    
    args = parser.parse_args()

    if not os.environ.get("LANGFUSE_PUBLIC_KEY") or not os.environ.get("LANGFUSE_SECRET_KEY"):
        print("‚ùå –û—à–∏–±–∫–∞: –ù–µ –∑–∞–¥–∞–Ω—ã LANGFUSE_PUBLIC_KEY –∏–ª–∏ LANGFUSE_SECRET_KEY")
        return

    langfuse = Langfuse()

    if not os.path.exists(args.file):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.file}")
        return
        
    items = load_jsonl(args.file)
    print(f"üìÑ –ü—Ä–æ—á–∏—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(items)}")

    try:
        dataset = langfuse.get_dataset(args.dataset_name)
        print(f"‚ÑπÔ∏è  –î–∞—Ç–∞—Å–µ—Ç '{args.dataset_name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã.")
    except:
        print(f"‚ú® –°–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç: '{args.dataset_name}'")
        langfuse.create_dataset(name=args.dataset_name)

    print("üöÄ –ó–∞–≥—Ä—É–∑–∫—É –≤ langfuse...")
    count = 0
    for item in items:
        input_data = item.get(args.input_key) or item.get('input')
        expected_output = item.get(args.output_key) or item.get('ground_truth')
        
        if not input_data:
            print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫ —Å—Ç—Ä–æ–∫–∏ (–Ω–µ—Ç –∫–ª—é—á–∞ '{args.input_key}'): {item}")
            continue

        metadata = {k: v for k, v in item.items() if k not in [args.input_key, args.output_key]}

        langfuse.create_dataset_item(
            dataset_name=args.dataset_name,
            input=input_data,
            expected_output=expected_output,
            metadata=metadata
        )
        count += 1

    langfuse.flush()
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {count} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç '{args.dataset_name}'")

if __name__ == "__main__":
    main()