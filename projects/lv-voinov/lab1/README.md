## Отчет по лабораторной 1

Модели Gemma-3n-E4B, GPT-OSS-20B, Qwen3-30B-Instruct, развернуты с помощью Ollama в дефолтном квантовании, запущены через python-библиотеку ollama.

Промпты (от DeepSeek V3.2):

1. Генерация

```Ты — автор популярного блога о продуктивности. Твоя задача — написать короткий, но вдохновляющий пост в LinkedIn (не более 3 абзацев) на основе идеи пользователя.

Используй следующий каркас:
1.  Заголовок-крючок: Придумай яркий и интригующий заголовок.
2.  Проблема: Кратко опиши распространенную проблему (используй идею пользователя ниже).
3.  Решение: Предложи метод из 2 шагов для её решения. Назови этот метод запоминающимся именем (например, "Принцип двух минут" или "Система чистого листа").
4.  Призыв к действию: Заверши пост открытым вопросом к аудитории, чтобы спровоцировать обсуждение в комментариях.

Идея пользователя: "Как перестать откладывать сложные звонки на потом?"

Стиль: Мотивирующий, энергичный, деловой, но неформальный. Используй эмодзи (2-3 штуки на весь пост) для расстановки акцентов.

Начни сразу с заголовка.
```

2. Классификация

```Классифицируй следующие пользовательские запросы в одну из трёх фиксированных категорий: ["Billing", "Tech support", "Sales"]. Ответ дай только в виде названия категории, без пояснений.

Список запросов:
1. "У меня не скачивается счет за прошлый месяц, вы можете прислать его на почту?"
2. "Расскажите, есть ли скидки при покупке более 10 лицензий?"
3. "Приложение постоянно вылетает при попытке открыть раздел настроек, что делать?"
4. "Я хотел бы отменить подписку, так как она мне больше не нужна."
5. "Ваш тариф 'Профессиональный' включает в себя возможность создания белых ярлыков?"
6. "Мой платеж прошел два раза, я вижу две одинаковые транзакции на своей карте. Помогите разобраться и верните средства."
7. "Перед покупкой хочу уточнить, совместим ли ваш программный продукт с операционной системой Linux?"
8. "После последнего обновления я не могу найти функцию экспорта данных в PDF. Она была удалена или перемещена?"
9. "Я представитель учебного заведения. Мы заинтересованы в оптовом заказе для компьютерного класса. Можете ли вы подготовить для нас коммерческое предложение?"
10. "Автоплатеж по моей подписке не сработал, хотя на карте есть средства. Как мне возобновить доступ к сервису?"
```

3. Извлечение/Суммаризация/Переформулирование

```Проанализируй предоставленный отзыв клиента и выполни три задачи:

1. Извлеки следующую информацию в формате JSON:
   - `product_name` (название товара)
   - `customer_sentiment` (настроение: "positive", "negative", "neutral")
   - `mentioned_features` (список упомянутых в отзыве характеристик товара)
   - `main_issue` (основная проблема или похвала, одним предложением)

2. Суммаризируй отзыв в одно-два предложения.

3. Переформулируй основную жалобу или предложение в виде формального запроса в службу поддержки.

Текст отзыва:
"Купил новый смартфон 'Solaris X5'. Дизайн просто фантастический, очень стильный и удобно лежит в руке. Экран просто огонь, цвета сочные. Но батарея, к сожалению, совсем не держит заряда, к вечеру уже приходится искать розетку, хотя продавали как устройство с долгим временем работы. И камера ночью снимает не очень, много шумов. В общем, для повседневных задач пойдет, но как основной смартфон для путешествий - не рекомендую."
```

### Бенчмарки

Измеряемые параметры:
- Количество токенов промпта
- Количество токенов ответа
- Общее время
- Время загрузки модели
- Время инференса модели
- Скорость инференса в токенах в секунду

Результаты бенчмарков с дефолтными параметрами находятся в ollama_benchmark_results.json

Измененные параметры: 'temperature': 0.1, 'top_p': 0.9, 'repeat_penalty': 1.2. Результаты в ollama_benchmark_results_modified.json

У Gemma-3n-E4B самая высокая скорость инференса - 25-26 токенов в секунду, у Qwen3-30B-A3B-Instruct скорость 15-17 токенов в секунду, у GPT-OSS-20B всего 10-11 токенов в секунду.

С 1 задачей все три модели справились. У Gemma изменение гиперпараметров не повлияло на ответ, ответы очень похожи. У Qwen и GPT есть ощутимые изменения между ответами. Ответ GPT с измененными гиперпараметрами вообще был на английском, вероятно из-за низкой температуры, при том что reasoning этой модели всегда ведется на английском.

С 2 задачей все модели справились, формат ответов идеально выдержан. Qwen и GPT набрали 10/10, Gemma в обоих случаях набрала 9/10.

В 3 задаче все модели также соблюдали формат ответов. Qwen и GPT указали на отрицательную направленность отзыва, Gemma - на нейтральную.