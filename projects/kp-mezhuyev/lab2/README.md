# Лабораторная работа №2 — Построение RAG-агента по документации

## Описание задания

Построить RAG (Retrieval Augmented Generation) агента для ответов на вопросы по документации FastAPI.

**Основные этапы:**
1. Выбрать и подготовить источники данных (не менее 50 страниц)
2. Спарсить источники в Markdown с сохранением структуры и метаданных
3. Разбить на чанки и построить эмбеддинги (dense/sparse)
4. Развернуть векторное хранилище и загрузить индекс
5. Измерить качество retrieval (Recall@k, Precision@k, MRR)
6. Реализовать RAG-пайплайн для генерации ответов с цитатами

## Использованные технологии

### Инфраструктура
- **Векторное хранилище:** Elasticsearch 9.2.3 (локально)
- **LLM:** Ollama (qwen2.5:3b через OpenAI-совместимый API)
- **Эмбеддинги:** intfloat/multilingual-e5-base (768-мерные векторы)
- **Токенизация:** tiktoken (cl100k_base encoding)

### Библиотеки
- sentence-transformers (эмбеддинги)
- elasticsearch (векторное хранилище)
- openai (LLM API)
- tiktoken (подсчет токенов)
- scikit-learn (метрики сходства)
- pyyaml (конфигурация)

### Корпус документов
- **Источник:** Документация FastAPI (https://github.com/fastapi/fastapi/tree/master/docs/ru)
- **Объем:** ~120 страниц документации
- **Формат:** Markdown файлы с иерархической структурой заголовков

## Выбранные конфигурации для сравнения

Проведено сравнение **2 конфигураций** для оценки влияния стратегии разбиения на качество retrieval:

### Конфигурация 1: Baseline (Recursive splitter, 1024 токена)
```yaml
chunking:
  splitter_type: 'recursive'
  chunk_size: 1024
  chunk_overlap: 128
  include_headers_in_text: true

embeddings:
  vectorization_type: 'dense'
  dense:
    model: 'intfloat/multilingual-e5-base'
    device: 'cpu'
```
- **Версия:** `4530f7569b81`
- **Количество чанков:** 371
- **Описание:** Рекурсивный сплиттер с большим размером чанка для сохранения контекста

### Конфигурация 2: Markdown splitter (512 токенов)
```yaml
chunking:
  splitter_type: 'markdown'
  chunk_size: 512
  chunk_overlap: 50
  include_headers_in_text: true
  header_levels: ['h1', 'h2', 'h3']

embeddings:
  vectorization_type: 'dense'
  dense:
    model: 'intfloat/multilingual-e5-base'
    device: 'cpu'
```
- **Версия:** `e6233de3342d`
- **Количество чанков:** 991
- **Описание:** Markdown-aware сплиттер с меньшим размером чанка для более точной гранулярности

## Результаты работы

### Метрики качества retrieval

Тестирование проведено на **10 вопросах** с ручной разметкой релевантных чанков.

#### Сравнительная таблица метрик (k=5)

| Конфигурация | Recall@5 | Precision@5 | MRR | Количество чанков |
|-------------|----------|-------------|-----|-------------------|
| **Baseline (Recursive, 1024)** | **0.177** | **0.220** | **0.350** | 371 |
| Markdown (512) | 0.114 | 0.140 | 0.253 | 991 |
| **Изменение** | **-36%** | **-36%** | **-28%** | **+167%** |

#### Детальные метрики по вопросам

**Baseline (Recursive, 1024):**
- Recall@5: min=0.0, max=0.833, mean=0.177, std=0.252
- Precision@5: min=0.0, max=1.0, mean=0.220, std=0.316
- MRR: min=0.0, max=1.0, mean=0.350, std=0.436

**Markdown (512):**
- Recall@5: min=0.0, max=0.6, mean=0.114, std=0.183
- Precision@5: min=0.0, max=0.6, mean=0.140, std=0.201
- MRR: min=0.0, max=1.0, mean=0.253, std=0.389

### Качественное сравнение ответов

Проведено тестирование генерации ответов на 2 вопроса для обеих конфигураций.

#### Вопрос 1: "Что такое FastAPI?"

**Baseline (Recursive, 1024):**
- **Длина ответа:** 467 токенов (примерно)
- **Релевантность источников:** 1.873-1.889 (высокая)
- **Качество:** Подробный ответ с детальным описанием основных компонентов FastAPI, включая импорт, создание экземпляра app, декораторы, функции операций пути, запуск сервера и развертывание
- **Источники:** Покрывают tutorial (first-steps), security, deployment (fastapicloud), about

**Markdown (512):**
- **Длина ответа:** 318 токенов (примерно)
- **Релевантность источников:** 1.886-1.905 (высокая)
- **Качество:** Более краткий и фокусированный ответ, акцент на OpenAPI спецификации и open source природе FastAPI
- **Источники:** Покрывают deployment, security, tutorial (first-steps), versions, index

**Вывод:** Baseline дает более детальный и структурированный ответ, Markdown — более лаконичный с фокусом на ключевых аспектах.

#### Вопрос 2: "Как работать с зависимостями в FastAPI?"

**Baseline (Recursive, 1024):**
- **Длина ответа:** 481 токен (примерно)
- **Релевантность источников:** 1.888-1.893 (очень высокая)
- **Качество:** Практический ответ с примерами кода, покрывает создание зависимостей, использование, подзависимости, кэширование
- **Источники:** global-dependencies, dependencies-in-path-operation-decorators, dependencies/index, advanced-dependencies, sub-dependencies

**Markdown (512):**
- **Длина ответа:** 485 токенов (примерно)
- **Релевантность источников:** 1.901-1.910 (очень высокая)
- **Качество:** Теоретический ответ с акцентом на типах зависимостей (глобальные, подзависимости, yield/scope), автоматическое управление
- **Источники:** sub-dependencies, features, bigger-applications, tutorial/index, advanced-dependencies

**Вывод:** Baseline дает практические примеры кода, Markdown — архитектурное описание системы зависимостей.

### Анализ различий

#### 1. Влияние размера чанка

**Baseline (1024 токена):**
- ✅ Лучшие метрики retrieval (Recall@5: 0.177, MRR: 0.350)
- ✅ Сохраняет больше контекста в одном чанке
- ✅ Меньше фрагментации документов
- ❌ Меньше гранулярность (371 чанк)
- ❌ Может включать нерелевантную информацию в чанке

**Markdown (512 токенов):**
- ✅ Более высокая гранулярность (991 чанк)
- ✅ Уважает структуру Markdown (заголовки h1-h3)
- ✅ Более точное разделение по семантическим единицам
- ❌ Хуже метрики retrieval (Recall@5: 0.114, MRR: 0.253)
- ❌ Возможная фрагментация связанной информации

#### 2. Влияние на качество ответов

**Детальность ответов:**
- Baseline генерирует более развернутые ответы с примерами кода
- Markdown генерирует более структурированные и концептуальные ответы

**Релевантность источников:**
- Обе конфигурации показывают высокую релевантность (>1.87)
- Markdown показывает чуть выше релевантность топ-1 документа

**Покрытие тем:**
- Baseline: фокус на практическом применении
- Markdown: фокус на архитектуре и концепциях

#### 3. Причины различий в метриках

**Почему Baseline лучше:**
1. **Проблема разметки:** `expected_chunks` размечались для Baseline конфигурации и перенесены через косинусную близость эмбеддингов для Markdown
2. **Фрагментация:** Markdown разбивает по заголовкам, что может разделить связанные параграфы на разные чанки
3. **Overlap:** Меньший overlap (50 vs 128) уменьшает шансы захвата пограничной информации
4. **Гранулярность:** Больше чанков (991 vs 371) означает, что релевантная информация распределена по большему количеству чанков, сложнее попасть в top-k

**Потенциал Markdown конфигурации:**
- При правильной разметке для меньшего размера чанка метрики могут быть выше
- Лучше подходит для вопросов, требующих точечной информации из одного раздела
- Может показать лучшие результаты при увеличении k (top-10, top-15)

## Выводы

### 1. Оптимальная конфигурация для FastAPI документации

**Рекомендуемая конфигурация: Baseline (Recursive, 1024)**

**Причины:**
- ✅ **Лучшие метрики retrieval** (+36% Recall@5, +28% MRR)
- ✅ **Более полные ответы** с примерами кода
- ✅ **Меньше фрагментации** контекста
- ✅ **Лучше для технической документации** где важен контекст

**Когда использовать Markdown (512):**
- Документация с четкой иерархической структурой (h1-h3)
- Вопросы требуют точечной информации из одного раздела
- Важна высокая гранулярность для точной атрибуции источников
- Большее значение k (top-10+) в retrieval

### 2. Влияние параметров чанкинга

**Размер чанка:**
- Большой chunk_size (1024) лучше для **контекстуальных вопросов**
- Малый chunk_size (512) лучше для **фактических вопросов**

**Overlap:**
- Больший overlap (128) помогает не потерять информацию на границах
- Меньший overlap (50) уменьшает дублирование, но может пропустить связи

**Тип сплиттера:**
- Recursive — универсальный, хорош для разной структуры
- Markdown — специализированный, требует четкой структуры документов

### 3. Ограничения и улучшения

**Текущие ограничения:**
1. Разметка `expected_chunks` привязана к одной конфигурации (baseline)
2. Перенос через косинусную близость не идеален (min_similarity=0.85)
3. Тестовый датасет мал (10 вопросов)

**Возможные улучшения:**
1. Увеличить размер тестового датасета (50+ вопросов)
2. Размечать expected_chunks независимо для каждой конфигурации
3. Тестировать гибридные подходы (dense + BM25)
4. Экспериментировать с re-ranking
5. Использовать квантование эмбеддингов для ускорения
6. Протестировать другие модели эмбеддингов (bge-m3, e5-large-v2)

### 4. Рекомендации по использованию

**Для production RAG-системы на FastAPI документации:**

1. **Конфигурация чанкинга:**
   - Использовать Recursive splitter с chunk_size=1024
   - Overlap=128 токенов для сохранения связей
   - Include_headers_in_text=true для контекста

2. **Эмбеддинги:**
   - multilingual-e5-base оптимален (качество/скорость)
   - Использовать правильные префиксы (query: / passage:)
   - Кэшировать эмбеддинги в Elasticsearch

3. **Retrieval:**
   - Top-k=5 достаточно для большинства вопросов
   - Можно увеличить до top-k=10 для сложных вопросов
   - Использовать cosine similarity через script_score в ES

4. **LLM генерация:**
   - qwen2.5:3b дает хорошее качество/скорость
   - temperature=0.3, max_tokens=512 для структурированных ответов
   - Включать источники в промпт для атрибуции

5. **Метрики и мониторинг:**
   - Отслеживать Recall@5, MRR для оценки retrieval
   - Использовать пользовательский фидбек для дообучения
   - Периодически пересобирать индекс при обновлении документации

## Структура проекта

```
lab2/
├── source/                          # Исходный код
│   ├── chunking.py                  # Стратегии разбиения на чанки
│   ├── embeddings.py                # Создание эмбеддингов (dense/sparse)
│   ├── md_processor.py              # Парсинг Markdown
│   ├── es_utils.py                  # Утилиты для Elasticsearch
│   ├── config_utils.py              # Загрузка/сохранение конфигурации
│   ├── build_index.py               # Построение чанков и эмбеддингов
│   ├── load_to_vector_store.py      # Загрузка в Elasticsearch
│   ├── evaluate.py                  # Вычисление метрик retrieval
│   ├── rag_pipeline.py              # RAG-пайплайн для генерации ответов
│   ├── run_experiments.py           # Запуск экспериментов
│   ├── generate_answer_examples.py  # Генерация примеров ответов
│   ├── transfer_expected_chunks.py  # Перенос разметки между версиями
│   ├── check_es_index.py            # Проверка индексов в ES
│   ├── clean_elasticsearch.py       # Очистка индексов
│   ├── config.yaml                  # Конфигурация
│   └── requirements.txt             # Зависимости
├── data/
│   ├── raw/                         # Исходная документация (Markdown)
│   ├── chunks/                      # Сохраненные чанки
│   │   ├── 4530f7569b81/           # Baseline (Recursive, 1024)
│   │   └── e6233de3342d/           # Markdown (512)
│   ├── index/                       # Метаданные индексов
│   │   ├── 4530f7569b81/
│   │   └── e6233de3342d/
│   └── evaluation/                  # Результаты оценки
│       ├── expected_chunks_4530f7569b81.json  # Разметка для Baseline
│       ├── expected_chunks_e6233de3342d.json  # Разметка для Markdown
│       ├── results_4530f7569b81.json          # Метрики Baseline
│       ├── experiment_markdown_512.json       # Метрики Markdown
│       ├── answer_examples.json               # Примеры ответов
│       └── transfer_result_*.json             # Результаты переноса разметки
└── README.md                        # Этот файл
```

## Инструкция по запуску

### 1. Установка зависимостей

```bash
cd lab2
pip install -r source/requirements.txt
```

### 2. Запустить настроенный Elasticsearch:
```bash
# Пример для Windows
cd ..
.\elasticsearch-9.2.3\bin\elasticsearch.bat
```

### 3. Построение индекса

```bash
# Baseline конфигурация (Recursive, 1024)
python source/build_index.py --config source/config.yaml

# Для другой конфигурации отредактируйте config.yaml
# и запустите снова
```

### 4. Загрузка в Elasticsearch

```bash
# Загрузить построенный индекс
python source/load_to_vector_store.py --version 4530f7569b81

# Проверить загрузку
python source/check_es_index.py
```

### 5. Оценка качества retrieval

```bash
# Оценить конкретную версию
python source/evaluate.py \
  --version 4530f7569b81 \
  --expected-chunks data/evaluation/expected_chunks_4530f7569b81.json \
  --output data/evaluation/results_4530f7569b81.json
```

### 6. Запуск RAG-пайплайна

```bash
# Интерактивный режим
python source/rag_pipeline.py --interactive

# Один вопрос
python source/rag_pipeline.py --query "Что такое FastAPI?"

# С указанием индекса
python source/rag_pipeline.py \
  --query "Как работать с зависимостями?" \
  --index-name fastapi_docs_baseline_recursive_1024
```

### 7. Запуск экспериментов

```bash
# Запустить все эксперименты (построение, загрузка, оценка)
python source/run_experiments.py
```

### 8. Генерация примеров ответов

```bash
# Сгенерировать ответы на тестовые вопросы
python source/generate_answer_examples.py
```

## Полезные скрипты

### Очистка индексов

```bash
# Посмотреть все индексы
python source/clean_elasticsearch.py --list

# Удалить конкретный индекс
python source/clean_elasticsearch.py --index fastapi_docs_old

# Удалить все индексы с паттерном
python source/clean_elasticsearch.py --pattern fastapi_docs --confirm
```

### Перенос разметки между версиями

```bash
# Перенести expected_chunks через косинусную близость эмбеддингов
python source/transfer_expected_chunks.py \
  --source-version 4530f7569b81 \
  --target-version e6233de3342d \
  --min-similarity 0.85
```

## Метрики retrieval

- **Recall@k:** Доля релевантных документов, найденных в топ-k
- **Precision@k:** Доля релевантных документов среди топ-k результатов
- **MRR (Mean Reciprocal Rank):** Среднее значение 1/rank первого релевантного документа