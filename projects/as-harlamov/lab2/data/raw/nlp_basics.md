# Основы обработки естественного языка

## Введение в NLP

### Что такое NLP?

Обработка естественного языка (Natural Language Processing, NLP) — это область искусственного интеллекта, которая фокусируется на взаимодействии между компьютерами и человеческим языком.

### Задачи NLP

Основные задачи NLP включают:
- Токенизация: разбиение текста на слова или токены
- Лемматизация: приведение слов к их базовой форме
- Стемминг: удаление аффиксов для получения корня слова
- Частеречная разметка (POS tagging): определение частей речи
- Распознавание именованных сущностей (NER): извлечение имен, мест, организаций
- Анализ тональности: определение эмоциональной окраски текста

## Предобработка текста

### Токенизация

Токенизация — это процесс разбиения текста на отдельные слова или токены. Это первый шаг в большинстве NLP-пайплайнов.

### Нормализация

Нормализация включает:
- Приведение к нижнему регистру
- Удаление пунктуации
- Удаление стоп-слов (часто встречающихся слов без смысловой нагрузки)
- Обработка чисел и специальных символов

### Лемматизация и стемминг

- Лемматизация: использует словарь и морфологический анализ для приведения слова к его базовой форме
- Стемминг: использует эвристические правила для удаления аффиксов

## Представление текста

### Мешок слов (Bag of Words)

Модель "мешок слов" представляет документ как неупорядоченный набор слов, игнорируя порядок и структуру.

### TF-IDF

TF-IDF (Term Frequency-Inverse Document Frequency) — это статистическая мера, которая оценивает важность слова в документе относительно коллекции документов.

TF-IDF = TF × IDF

где:
- TF (Term Frequency): частота слова в документе
- IDF (Inverse Document Frequency): обратная частота документа

### Word Embeddings

Word embeddings представляют слова как плотные векторы в многомерном пространстве, где семантически похожие слова расположены близко друг к другу.

### Word2Vec

Word2Vec — это алгоритм для обучения word embeddings:
- Skip-gram: предсказывает контекстные слова по целевому слову
- CBOW (Continuous Bag of Words): предсказывает целевое слово по контексту

### GloVe

GloVe (Global Vectors) обучает embeddings на основе глобальной статистики совстречаемости слов.

### FastText

FastText расширяет Word2Vec, рассматривая подстроки слов, что помогает обрабатывать редкие слова и слова с опечатками.

## Современные подходы

### Контекстуальные embeddings

В отличие от статических embeddings, контекстуальные embeddings генерируют разные представления для одного слова в разных контекстах.

### ELMo

ELMo (Embeddings from Language Models) использует двунаправленные LSTM для создания контекстуальных embeddings.

### BERT

BERT (Bidirectional Encoder Representations from Transformers) использует трансформеры для создания глубоких двунаправленных представлений.

### GPT

GPT (Generative Pre-trained Transformer) — это авторегрессионная модель, которая генерирует текст слева направо.

## Задачи NLP

### Классификация текста

Классификация текста включает:
- Классификацию документов
- Анализ тональности
- Определение темы

### Машинный перевод

Машинный перевод использует нейронные сети для перевода текста с одного языка на другой. Современные системы используют архитектуры seq2seq с механизмом внимания.

### Вопросно-ответные системы

Вопросно-ответные системы извлекают ответы на вопросы из текста. Современные системы используют:
- Reading comprehension: поиск ответа в предоставленном контексте
- Open-domain QA: поиск ответа в большой коллекции документов

### Генерация текста

Генерация текста включает:
- Завершение предложений
- Создание резюме
- Творческое письмо

### Извлечение информации

Извлечение информации включает:
- Распознавание именованных сущностей
- Извлечение отношений
- Извлечение событий

## Метрики оценки

### Для классификации

- Accuracy: общая точность
- Precision: точность положительных предсказаний
- Recall: полнота положительных случаев
- F1-score: гармоническое среднее precision и recall

### Для машинного перевода

- BLEU: оценка качества перевода на основе n-грамм
- METEOR: учитывает синонимы и порядок слов
- ROUGE: для оценки суммаризации

### Для вопросно-ответных систем

- Exact Match: точное совпадение ответа
- F1-score: перекрытие токенов между предсказанным и правильным ответом

## Инструменты и библиотеки

### NLTK

Natural Language Toolkit (NLTK) — это платформа для работы с человеческим языком в Python.

### spaCy

spaCy — это библиотека для продвинутой обработки естественного языка с акцентом на производительность.

### Transformers

Библиотека Transformers от Hugging Face предоставляет тысячи предобученных моделей для различных NLP-задач.

### Gensim

Gensim специализируется на тематическом моделировании и извлечении семантических тем из документов.

