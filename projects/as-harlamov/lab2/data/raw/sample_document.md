# Введение в машинное обучение

## Что такое машинное обучение?

Машинное обучение (Machine Learning, ML) — это подраздел искусственного интеллекта, который изучает алгоритмы и статистические модели, которые компьютерные системы используют для выполнения задачи без явных инструкций, полагаясь на паттерны и выводы вместо этого.

Машинное обучение строится на обучении с данными. Вместо того чтобы программировать компьютер для выполнения конкретной задачи, мы предоставляем ему данные и позволяем ему учиться на этих данных.

## Типы машинного обучения

### Обучение с учителем (Supervised Learning)

Обучение с учителем — это тип машинного обучения, при котором алгоритм учится на размеченных данных. Каждый пример в обучающем наборе данных имеет входные данные и соответствующий правильный выход.

Примеры задач обучения с учителем:
- Классификация: определение категории объекта (например, спам или не спам)
- Регрессия: предсказание числового значения (например, цена дома)

### Обучение без учителя (Unsupervised Learning)

Обучение без учителя — это тип машинного обучения, при котором алгоритм учится на данных без меток. Цель состоит в том, чтобы найти скрытые паттерны или структуры в данных.

Примеры задач обучения без учителя:
- Кластеризация: группировка похожих объектов
- Понижение размерности: уменьшение количества признаков

### Обучение с подкреплением (Reinforcement Learning)

Обучение с подкреплением — это тип машинного обучения, при котором агент учится принимать решения, взаимодействуя со средой и получая обратную связь в виде наград или штрафов.

## Нейронные сети

### Что такое нейронная сеть?

Нейронная сеть — это вычислительная модель, вдохновленная биологическими нейронными сетями, которые составляют мозг животных. Нейронная сеть состоит из взаимосвязанных узлов (нейронов), которые обрабатывают информацию.

### Архитектура нейронной сети

Нейронная сеть состоит из:
- Входного слоя: получает входные данные
- Скрытых слоев: обрабатывают информацию
- Выходного слоя: производит результат

Каждый нейрон принимает входные данные, применяет к ним веса и функцию активации, и передает результат следующему слою.

### Обучение нейронной сети

Обучение нейронной сети включает:
1. Прямой проход (forward pass): данные проходят через сеть
2. Вычисление ошибки: сравнение выхода с ожидаемым результатом
3. Обратный проход (backward pass): распространение ошибки назад и обновление весов

## Глубокое обучение

### Что такое глубокое обучение?

Глубокое обучение (Deep Learning) — это подраздел машинного обучения, который использует нейронные сети с множеством слоев (глубокие нейронные сети) для моделирования и понимания сложных паттернов.

Глубокое обучение особенно эффективно для:
- Распознавания изображений
- Обработки естественного языка
- Распознавания речи

### Преимущества глубокого обучения

1. Автоматическое извлечение признаков: сеть сама учится находить важные признаки
2. Масштабируемость: производительность улучшается с увеличением данных
3. Гибкость: одна архитектура может применяться к разным задачам

## Метрики оценки моделей

### Метрики для классификации

- Точность (Accuracy): доля правильных предсказаний
- Точность (Precision): доля положительных предсказаний, которые действительно положительны
- Полнота (Recall): доля положительных случаев, которые были правильно идентифицированы
- F1-мера: гармоническое среднее точности и полноты

### Метрики для регрессии

- Средняя квадратичная ошибка (MSE): среднее квадратов разностей между предсказанными и фактическими значениями
- Средняя абсолютная ошибка (MAE): среднее абсолютных разностей
- Коэффициент детерминации (R²): мера того, насколько хорошо модель объясняет вариацию данных

## Процесс обучения модели

### Этапы обучения

1. Подготовка данных: сбор, очистка и предобработка данных
2. Разделение данных: разделение на обучающую, валидационную и тестовую выборки
3. Выбор модели: выбор подходящего алгоритма
4. Обучение: обучение модели на обучающих данных
5. Валидация: оценка на валидационной выборке
6. Тестирование: финальная оценка на тестовой выборке

### Гиперпараметры

Гиперпараметры — это параметры, которые устанавливаются до начала обучения и не изменяются в процессе обучения. Примеры:
- Скорость обучения (learning rate)
- Количество эпох
- Размер батча
- Количество слоев в нейронной сети

## Переобучение и недообучение

### Переобучение (Overfitting)

Переобучение происходит, когда модель слишком хорошо запоминает обучающие данные и плохо обобщается на новые данные. Признаки переобучения:
- Высокая точность на обучающих данных
- Низкая точность на тестовых данных

### Недообучение (Underfitting)

Недообучение происходит, когда модель слишком проста и не может уловить паттерны в данных. Признаки недообучения:
- Низкая точность на обучающих данных
- Низкая точность на тестовых данных

## Методы регуляризации

### L1 и L2 регуляризация

- L1 регуляризация (Lasso): добавляет штраф за сумму абсолютных значений весов
- L2 регуляризация (Ridge): добавляет штраф за сумму квадратов весов

### Dropout

Dropout — это техника регуляризации, при которой случайно отключаются некоторые нейроны во время обучения, что предотвращает переобучение.

### Ранняя остановка (Early Stopping)

Ранняя остановка — это метод, при котором обучение прекращается, когда производительность на валидационной выборке перестает улучшаться.

## Градиентный спуск

### Что такое градиентный спуск?

Градиентный спуск — это алгоритм оптимизации, используемый для минимизации функции потерь путем итеративного движения в направлении наискорейшего спуска, определяемого отрицательным градиентом.

### Типы градиентного спуска

1. Пакетный градиентный спуск (Batch Gradient Descent): использует все данные для каждого обновления
2. Стохастический градиентный спуск (SGD): использует один пример для каждого обновления
3. Мини-пакетный градиентный спуск (Mini-batch SGD): использует небольшую выборку данных

### Оптимизаторы

Современные оптимизаторы улучшают базовый градиентный спуск:
- Adam: адаптивная оценка моментов
- RMSprop: адаптивная скорость обучения
- AdaGrad: адаптивный градиент

## Валидация модели

### Кросс-валидация

Кросс-валидация — это метод оценки производительности модели путем разделения данных на несколько фолдов и обучения на разных комбинациях фолдов.

### Типы кросс-валидации

- K-fold кросс-валидация: данные разделяются на K фолдов
- Стратифицированная кросс-валидация: сохраняет пропорции классов в каждом фолде
- Временная кросс-валидация: используется для временных рядов

### Разделение данных

Типичное разделение:
- Обучающая выборка: 60-80%
- Валидационная выборка: 10-20%
- Тестовая выборка: 10-20%

