# Лабораторная работа №3: Развертывание Langfuse для логирования LLM-запросов

## Описание задания

В рамках лабораторной работы выполнено развертывание системы логирования **Langfuse** и её интеграция в RAG-приложение (из предыдущих лабораторных работ). Цель работы — организовать централизованное логирование запросов к LLM, трассировку всех этапов RAG-пайплайна, загрузку тестового датасета и автоматическую оценку метрик качества (Recall@k, Precision@k, MRR) через механизм Experiment Run.

Основные этапы:
1. Развертывание Langfuse локально с помощью Docker Compose.
2. Интеграция Langfuse в RAG-приложение для логирования запросов, ответов и промежуточных шагов.
3. Загрузка датасета вопросов-ответов в Langfuse.
4. Проведение оценки RAG-системы с вычислением метрик и их сохранением в Langfuse.

## Использованные технологии и модели

- **LLM**: Mistral (через Ollama)
- **Фреймворки**:
  - Langfuse (v2.85.0) — платформа для логирования и трассировки LLM
  - Elasticsearch — для гибридного поиска документов
  - Sentence Transformers — для векторных эмбеддингов
- **Библиотеки**:
  - `langfuse` (Python SDK)
  - `requests`
  - `python-dotenv`
  - `elasticsearch`
  - `sentence-transformers`
- **Инфраструктура**:
  - Docker, Docker Compose
  - PostgreSQL (как БД для Langfuse)

## Результаты работы

1. **Развернут Langfuse**:
   - Локальный инстанс доступен по адресу `http://localhost:3000`.
   - Настроены переменные окружения для подключения приложения.

2. **Интегрировано логирование**:
   - Реализован скрипт `rag_chat_langfuse.py`, который логирует:
     - Пользовательские запросы и ответы LLM.
     - Процесс retrieval (гибридный поиск) с метаданными (пути, релевантность).
     - Промежуточные шаги через механизм `span` и `generation` (V2 API).
   - Каждый запрос связан с `trace_id`, что позволяет отслеживать полный цикл взаимодействия.

3. **Загружен датасет**:
   - Датасет `python_docs_qa` (15 вопросов по документации Python) загружен в Langfuse через скрипт `load_dataset.py`.
   - Каждый элемент содержит `input` (вопрос) и `expected_output` (список релевантных чанков).

4. **Проведена оценка метрик**:
   - Реализован скрипт `evaluate_langfuse.py` для запуска эксперимента (`Experiment Run`).
   - Вычислены retrieval-метрики: `Recall@k`, `Precision@k`, `MRR` (для k=5, 10).
   - Метрики автоматически логируются в Langfuse как `scores` и доступны для анализа в веб-интерфейсе.

## Выводы

1. **Централизованное логирование** значительно упрощает отладку и анализ работы RAG-системы. Langfuse предоставляет удобный интерфейс для отслеживания запросов, ответов и промежуточных шагов.
2. **Трассировка (tracing)** позволяет связать все этапы пайплайна (retrieval → generation) в единый контекст, что особенно полезно для сложных сценариев (например, RAG с несколькими источниками).
3. **Автоматическая оценка метрик** через Experiment Run экономит время на ручную проверку и даёт объективные данные для сравнения разных конфигураций (например, изменение `top_k` или модели LLM).
4. **Проблемы и решения**:
   - **Проблема**: Несовместимость V3 и V2 API Langfuse.
     
     **Решение**: Использованы методы V2 API (`trace()`, `span()`, `generation()`, `score()`).

## Инструкция по запуску

### 1. Подготовка окружения
```bash
# Клонируйте репозиторий с лабораторными работами
git clone <repository-url>
cd lab3

# Установите зависимости
pip install -r requirements.txt
```
### 2. Запуск Langfuse
``` bash
# Запустите Langfuse через Docker Compose
docker-compose up -d

# Проверьте доступность интерфейса
# Откройте в браузере: http://localhost:3000
```
### 3. Настройка переменных окружения

Создайте файл .env в корне проекта:
``` env
# Langfuse
LANGFUSE_PUBLIC_KEY=<ваш_public_key>
LANGFUSE_SECRET_KEY=<ваш_secret_key>
LANGFUSE_HOST=http://localhost:3000

# Ollama
OLLAMA_URL=http://localhost:11434/api/generate
OLLAMA_MODEL=mistral
```
### 4. Загрузка датасета в Langfuse
``` bash
python load_dataset.py
```

### 5. Запуск RAG-чата с логированием
``` bash
python rag_chat_langfuse.py
```

### 6. Запуск оценки метрик
``` bash
# Базовый запуск
python evaluate_langfuse.py

# С кастомными параметрами
python evaluate_langfuse.py --experiment-name "my_experiment" --top-k 10
```

### 7. Просмотр результатов
- Откройте Langfuse UI: http://localhost:3000
- Перейдите в раздел Traces для просмотра запросов.
- В разделе Experiments найдите ваш эксперимент и анализируйте метрики.
- В разделе Datasets проверьте загруженные вопросы.

### 8. Остановка Langfuse
``` bash
docker-compose down
```

*Примечание: Перед запуском убедитесь, что:*
- *Установлены Docker и Docker Compose.*
- *Запущен Ollama с моделью mistral (или другой выбранной моделью).*
- *Elasticsearch и база данных для гибридного поиска настроены (из LR2).*