# Лабораторная работа №2 — Построение RAG-агента по документации

## Описание задания

Полная реализация RAG-пайплайна: от парсинга источников до готового агента с оценкой качества.

### Задание 1: Выбор и подготовка источников данных

**Выбранный корпус документов:**
- Источник: Публичные репозитории GitHub нескольких пользователей:
  - [IlyaDanilenko](https://github.com/IlyaDanilenko) - 38 репозиториев
  - [ADmangarakov](https://github.com/ADmangarakov) - 4 репозитория
  - [sanchous1000](https://github.com/sanchous1000) - 7 репозиториев
  - [ivanlabb](https://github.com/ivanlabb) - 1 репозиторий
- Тип: README файлы из репозиториев
- Объем: 50 документов из 44 уникальных репозиториев, общий объем 88,088 символов (~44 страницы текста)

**Подготовленные вопросы:**
Создан файл `source/questions.md` с 20 репрезентативными вопросами, охватывающими:
- Общие вопросы о проектах и технологиях
- Вопросы по конкретным проектам (Geoscan Pioneer Max, pyarinst и др.)
- Технические детали установки и использования
- Вопросы по документации

### Задание 2: Парсинг источников в Markdown

**Реализованный функционал:**
- Скрипт `parse_github_repos.py` для автоматического парсинга README из репозиториев GitHub
- Использование GitHub API для получения списка репозиториев и содержимого README
- Нормализация Markdown с сохранением структуры (заголовки, списки, таблицы)
- Добавление метаданных в формате YAML front matter:
  - `source`: Источник данных (GitHub)
  - `repository`: Имя репозитория
  - `repository_url`: URL репозитория
  - `path`: Путь к файлу README
  - `date_parsed`: Дата парсинга
  - `date_updated`: Дата последнего обновления репозитория
  - `language`: Основной язык программирования
  - `description`: Описание репозитория
  - `stars`: Количество звезд

**Результаты парсинга:**
- Всего обработано: 50 репозиториев
- Успешно спарсено: 50 документов из 44 уникальных репозиториев с README
- Сохранено в директории: `source/parsed_docs/`
- Создана сводка: `source/parsed_docs/parsing_summary.json`
- Дата последнего парсинга: 2025-11-18

### Задание 3: Разбиение на чанки и построение эмбеддингов

**Реализованный функционал:**
- Скрипт `build_index.py` для разбиения документов на чанки и построения эмбеддингов
- Поддержка гибридного разбиения: по заголовкам Markdown + рекурсивное разбиение
- Конфигурируемые параметры через `config/config.json`:
  - Тип сплиттера (hybrid/recursive)
  - Размер чанка (chunk_size)
  - Перекрытие (chunk_overlap)
  - Включение заголовков в текст
- Построение эмбеддингов:
  - **Dense**: SentenceTransformer модели (по умолчанию `intfloat/multilingual-e5-large`)
  - **Sparse**: BM25 для keyword-based поиска
  - **Hybrid**: Комбинация dense и sparse
- Версионирование: каждая конфигурация сохраняется в отдельную папку `v_{hash}`
- Автоматическое определение устройства (MPS/CUDA/CPU)

**Результаты:**
- Чанки сохранены в `chunks/v_*/chunks.json`
- Dense эмбеддинги в `chunks/v_*/dense_embeddings.pkl`
- Sparse модель (BM25) в `chunks/v_*/sparse_model.pkl`
- Метаданные конфигурации в `chunks/v_*/metadata.json`
- Всего создано чанков: 309 (для текущей конфигурации v_04a1af15)

### Задание 4: Развертывание векторного хранилища

**Реализованный функционал:**
- Скрипт `load_to_vector_store.py` для загрузки в Faiss
- Поддержка различных типов индексов:
  - **HNSW**: Приближенный поиск с настраиваемыми параметрами (M, ef_construction, ef_search)
  - **Flat**: Точный поиск (L2 расстояние)
  - **IVF**: Индекс с квантованием
- Автоматическая загрузка чанков и эмбеддингов из последней версии
- Сохранение индекса и метаданных
- Поддержка пересборки индекса (флаг `--rebuild`)

**Результаты:**
- Индекс сохранен в `faiss_index/index.faiss`
- Метаданные в `faiss_index/metadata.json`
- Ссылки на чанки в `faiss_index/chunks_ref.json`

### Задание 5: Метрики и оценка качества retrieval/QA

**Реализованный функционал:**
- Скрипт `evaluate_retrieval.py` для оценки качества retrieval
- Скрипт `generate_ground_truth.py` для автоматической генерации ground truth
- Скрипт `compare_configs.py` для сравнения разных конфигураций
- Метрики:
  - **Recall@k**: Доля найденных релевантных документов
  - **Precision@k**: Точность среди топ-k результатов
  - **MRR**: Mean Reciprocal Rank
- Поддержка разных типов поиска:
  - Dense (семантический поиск)
  - Sparse (BM25 keyword search)
  - Hybrid (комбинация dense и sparse)
- Сравнение конфигураций с выводом таблиц результатов

**Результаты:**
- Ground truth сохранен в `ground_truth.json`
- Результаты оценки в `evaluation_results.json`
- Сравнительные таблицы в консоли

### Задание 6: RAG-пайплайн

**Реализованный функционал:**
- Скрипт `rag_pipeline.py` для интерактивного общения с RAG-агентом
- Интеграция с LLM через Ollama API (как в lab1)
- Этапы пайплайна:
  1. Векторизация запроса пользователя
  2. Поиск релевантных чанков (dense/sparse/hybrid)
  3. Форматирование контекста с метаданными
  4. Сборка промпта для LLM
  5. Генерация ответа с цитатами источников
- Поддержка различных типов поиска
- Форматирование ответов с указанием источников

**Использование:**
```bash
python3 rag_pipeline.py --search-type hybrid --top-k 5
```

## Использованные технологии и библиотеки

- **Python 3**
- **requests**: Для работы с GitHub API
- **GitHub REST API v3**: Для получения данных о репозиториях и README
- **langchain**: Для разбиения документов на чанки
- **sentence-transformers**: Для построения dense эмбеддингов
- **rank-bm25**: Для sparse эмбеддингов (BM25)
- **faiss**: Для векторного поиска
- **numpy**: Для работы с массивами
- **openai**: Для работы с LLM через Ollama API
- **torch**: Для работы с моделями на GPU/CPU/MPS

## Структура проекта

```
lab2/
├── source/
│   ├── parse_github_repos.py     # Задание 1-2: Парсинг README из GitHub
│   ├── build_index.py            # Задание 3: Разбиение на чанки и эмбеддинги
│   ├── load_to_vector_store.py   # Задание 4: Загрузка в Faiss
│   ├── generate_ground_truth.py  # Генерация ground truth для оценки
│   ├── evaluate_retrieval.py      # Задание 5: Оценка качества retrieval
│   ├── compare_configs.py        # Задание 5: Сравнение конфигураций
│   ├── rag_pipeline.py           # Задание 6: RAG-пайплайн
│   ├── questions.md              # 20 репрезентативных вопросов
│   ├── requirements.txt          # Зависимости проекта
│   ├── config/
│   │   └── config.json           # Конфигурация сплиттера и эмбеддингов
│   ├── utils/                    # Общие утилиты
│   │   ├── __init__.py           # Экспорт всех функций
│   │   ├── utils.py              # Утилиты (get_device, get_config_hash, tokenize)
│   │   ├── data_loader.py        # Загрузка данных (questions, chunks, documents)
│   │   └── metrics.py            # Метрики оценки (Recall@k, Precision@k, MRR)
│   ├── parsed_docs/              # Спарсенные README файлы
│   │   ├── *_README.md           # Нормализованные README с метаданными
│   │   └── parsing_summary.json  # Сводка о парсинге
│   ├── chunks/                   # Чанки и эмбеддинги (версионирование)
│   │   └── v_*/                  # Версии по хешу конфигурации
│   │       ├── chunks.json
│   │       ├── dense_embeddings.pkl
│   │       ├── sparse_model.pkl
│   │       └── metadata.json
│   ├── faiss_index/              # Индекс Faiss
│   │   ├── index.faiss
│   │   ├── metadata.json
│   │   └── chunks_ref.json
│   ├── ground_truth.json         # Релевантные чанки для вопросов (опционально)
│   └── evaluation_results.json   # Результаты оценки
└── README.md                     # Этот файл
```

## Результаты работы

### Статистика парсинга

- **Всего обработано репозиториев**: 50
- **Уникальных репозиториев с README**: 44
- **Общий объем текста**: 88,088 символов
- **Примерный объем**: ~44 страницы (при расчете 2000 символов на страницу)
- **Источники данных**:
  - IlyaDanilenko: 38 репозиториев
  - ADmangarakov: 4 репозитория
  - sanchous1000: 7 репозиториев
  - ivanlabb: 1 репозиторий

### Примеры спарсенных репозиториев

1. **geoscan_pioneer_max** - Репозиторий Geoscan Pioneer Max (CMake, 12 звезд)
2. **pyarinst** - Python SDK для Arinst устройств (Python, 7 звезд)
3. **pioneer-raspuart** - Geoscan Pioneer с Raspberry Pi Tutorial (5 звезд)
4. **gs_vision**, **gs_flight**, **gs_core** - Различные компоненты Geoscan
5. И другие проекты, связанные с робототехникой, ROS, веб-разработкой

### Формат сохраненных файлов

Каждый спарсенный README сохранен в формате:

```markdown
---
source: GitHub
repository: название_репозитория
repository_url: https://github.com/...
path: README.md
date_parsed: 2025-11-18T22:03:10.895401
date_updated: 2024-11-10T16:27:05Z
language: Python
description: Описание репозитория
stars: 7
---

[Исходное содержимое README с сохранением структуры]
```

### Результаты оценки качества retrieval

Оценка проведена на 20 вопросах из `questions.md` с использованием следующих метрик:
- **Recall@k**: Доля найденных релевантных документов среди топ-k результатов
- **Precision@k**: Точность среди топ-k результатов
- **MRR**: Mean Reciprocal Rank (средний обратный ранг первого релевантного документа)

**Конфигурация оценки:**
- Модель dense эмбеддингов: `intfloat/multilingual-e5-large`
- Значения k: 5, 10
- Количество вопросов: 20

#### Dense поиск (семантический поиск)

| Метрика | Среднее значение | Стандартное отклонение |
|---------|------------------|------------------------|
| Recall@5 | 1.00 | 0.00 |
| Precision@5 | 1.00 | 0.00 |
| Recall@10 | 1.00 | 0.00 |
| Precision@10 | 0.50 | 0.00 |
| MRR | 1.00 | 0.00 |

**Выводы:** Dense поиск показал отличные результаты с полным покрытием (Recall@5 = 1.0) и идеальной точностью на топ-5 результатах. Все релевантные документы находятся в первой пятерке результатов.

#### Sparse поиск (BM25 keyword search)

| Метрика | Среднее значение | Стандартное отклонение |
|---------|------------------|------------------------|
| Recall@5 | 0.46 | 0.31 |
| Precision@5 | 0.46 | 0.31 |
| Recall@10 | 0.58 | 0.33 |
| Precision@10 | 0.29 | 0.17 |
| MRR | 0.75 | 0.39 |

**Выводы:** Sparse поиск показал более низкие результаты по сравнению с dense поиском. Это связано с тем, что BM25 работает на основе точного совпадения ключевых слов, что может быть менее эффективно для семантически похожих, но лексически различных запросов.

#### Hybrid поиск (комбинация dense и sparse)

| Метрика | Среднее значение | Стандартное отклонение |
|---------|------------------|------------------------|
| Recall@5 | 0.71 | 0.20 |
| Precision@5 | 0.71 | 0.20 |
| Recall@10 | 0.96 | 0.08 |
| Precision@10 | 0.48 | 0.04 |
| MRR | 0.95 | 0.15 |

**Выводы:** Hybrid подход показал хорошие результаты, особенно на Recall@10 (0.96), что означает, что почти все релевантные документы находятся в топ-10 результатах. MRR = 0.95 указывает на то, что релевантные документы обычно находятся в начале списка результатов.

#### Сравнительный анализ

1. **Dense поиск** показал наилучшие результаты по всем метрикам, что подтверждает эффективность семантического поиска для данного корпуса документов.
2. **Hybrid поиск** демонстрирует хороший баланс между точностью и полнотой, особенно при увеличении k до 10.
3. **Sparse поиск** показал наименьшую эффективность, что может быть связано с особенностями корпуса (техническая документация с терминологией).

## Инструкция по запуску

### 1. Установка зависимостей

```bash
cd projects/ie-danilenko/lab2/source
pip install -r requirements.txt
```

### 2. Парсинг источников (Задание 1-2)

```bash
python3 parse_github_repos.py
```

Скрипт автоматически:
- Получает список всех публичных репозиториев
- Для каждого репозитория пытается найти README
- Нормализует содержимое и добавляет метаданные
- Сохраняет результаты в директорию `parsed_docs/`

### 3. Построение индекса (Задание 3)

```bash
python3 build_index.py
```

Скрипт:
- Загружает документы из `parsed_docs/`
- Разбивает на чанки согласно конфигурации в `config/config.json`
- Строит dense и sparse эмбеддинги
- Сохраняет результаты в `chunks/v_{hash}/`

**Настройка конфигурации:**
Отредактируйте `config/config.json` для изменения параметров:
- `splitter.type`: "hybrid" или "recursive"
- `splitter.chunk_size`: размер чанка (по умолчанию 500)
- `splitter.chunk_overlap`: перекрытие (по умолчанию 50)
- `embeddings.dense.model`: модель для dense эмбеддингов

### 4. Загрузка в векторное хранилище (Задание 4)

```bash
python3 load_to_vector_store.py --chunks-dir chunks --index-dir faiss_index
```

Опции:
- `--chunks-dir`: директория с чанками (по умолчанию `chunks`)
- `--index-dir`: директория для индекса (по умолчанию `faiss_index`)
- `--index-type`: тип индекса (HNSW/Flat/IVF, по умолчанию HNSW)
- `--rebuild`: пересобрать индекс даже если он существует

### 5. Генерация ground truth (опционально)

```bash
python3 generate_ground_truth.py --questions-file questions.md --chunks-dir chunks
```

Примечание: Ground truth файл будет создан в текущей директории как `ground_truth.json`.

### 6. Оценка качества retrieval (Задание 5)

```bash
python3 evaluate_retrieval.py \
    --faiss-index-dir faiss_index \
    --chunks-dir chunks \
    --questions-file questions.md \
    --ground-truth-file ground_truth.json \
    --search-types dense sparse hybrid
```

### 7. Сравнение конфигураций (Задание 5)

```bash
python3 compare_configs.py --configs config/config1.json config/config2.json
```

### 8. Запуск RAG-пайплайна (Задание 6)

```bash
python3 rag_pipeline.py \
    --faiss-index-dir faiss_index \
    --chunks-dir chunks \
    --search-type hybrid \
    --top-k 5
```

После запуска откроется интерактивный режим для общения с агентом.

## Выводы

1. **Успешно выполнено задание 1**: Выбран корпус документов (README из репозиториев GitHub), подготовлено 20 репрезентативных вопросов.

2. **Успешно выполнено задание 2**: Реализован скрипт для парсинга README в нормализованный Markdown с метаданными.

3. **Успешно выполнено задание 3**: Реализовано разбиение на чанки с поддержкой гибридного подхода и построение dense/sparse эмбеддингов с версионированием.

4. **Успешно выполнено задание 4**: Развернуто векторное хранилище на базе Faiss с поддержкой различных типов индексов (HNSW, Flat, IVF).

5. **Успешно выполнено задание 5**: Реализована оценка качества retrieval с метриками Recall@k, Precision@k, MRR и сравнение различных конфигураций.

6. **Успешно выполнено задание 6**: Реализован полнофункциональный RAG-пайплайн с интеграцией LLM через Ollama API.