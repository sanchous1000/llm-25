# Лабораторная работа №1

## 1. Описание задания
В рамках лабораторной работы было проведено сравнительное исследование производительности и качества работы трех различных языковых моделей малого размера.

Эксперименты включали три различных типа задач:
1. Генерация текста: генерация пословиц о погоде
2. Классификация текстов: разделение заголовков новостей на категории SPORT, POLITICS, EMERGENCY
3. Суммаризация текста: извлечение ключевой информации из абстракта научной статьи

Для каждой модели тестировались два набора параметров: дефолтный и finetuned (`temperature=0.2`, `top_k=100`).

## 2. Использованные технологии и модели

**Языковые модели:**
* `Llama 3.2:1b` - модель от Meta с 1 миллиардом параметров
* `Gemma 3:270m` - модель от Google с 270 миллионами параметров
* `Qwen 2.5:0.5b` - модель от Alibaba с 500 миллионами параметров

**Инструменты**: `ollama`, `python`

## 3. Результаты работы
### Качественные результаты
**Задача 1:** в целом справились все модели, но Llama сгенерировала наиболее осмысленные пословицы. Qwen создавала длинные, но менее структурированные тексты, Gemma - короткие релевантные фразы, но далекие от пословиц.

**Задача 2:** категории задавались в системном промпте. Qwen и Gemma придумывали новые категории, а также все модели допускали ошибки в форматировании. Llama выдавала наиболее корректные результаты даже в спорных случаях.

**Задача 3:** все модели справились с задачей, но Llama 3.2:1b дала наиболее структурированные и полные резюме. Finetuned параметры улучшили качество ответов для всех моделей.

### Производительность
| Модель | Число параметров | Время загрузки, с | Скорость генерации, токен/с |
|-|-|-|-|
| `Gemma3` | 270m | 6.43 | 35.55 |
| `Qwen2.5` | 500m | 1.42 | 30.62 |
| `Llama3.2` | 1b | 10.04 | 15.9 |

## 4. Выводы
1. **Соотношение размер-качество**: Qwen 2.5:0.5b показала хорошую производительность и качество ответов, особенно в задачах генерации текста.
2. **Влияние параметров**: finetuned параметры немного улучшили ответы моделей в задачах генерации. Несмотря на то, что оба параметра отвечают за вариативность ответов моделей, установка их в противоположные значения все равно сделала ответы более вариативными.
3. **Проблемы:** модели с меньшим числом параметров выдавали нестабильную классификацию, а также генерировали менее структурированные ответы. Решение проблемы - улучшение промптов, дальнейший подбор параметров.

## 5. Инструкция по запуску
1. Установить `Ollama`, `jq`, загрузить модели командой `ollama pull <MODEL_NAME>`
2. Запустить Ollama-сервер: `ollama serve`.
3. Запустить скрипты для получения csv-файлов и статистики. Затем запустить все ячейки в юпитер-ноутбуке для получения сводной статистики и отображения.
    ```bash
    bash t1.sh
    bash t2.sh
    bash t3.sh
    ```

