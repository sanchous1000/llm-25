import os
import sys
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
import click
import time
sys.path.insert(0, str(Path(__file__).parent.parent))
from source.utils import load_config
from source.embeddings import DenseEmbedder
from qdrant_client import QdrantClient
from openai import OpenAI


class RAGPipeline:
    
    def __init__(self, config_path = 'config.yaml'):
        self.config = load_config(config_path)
        qdrant_config = self.config.get('qdrant', {})
        self.host = qdrant_config.get('host', 'localhost')
        self.port = qdrant_config.get('port', 6333)
        self.collection_name = qdrant_config.get('collection_name', 'documents')
        self.ef_search = qdrant_config.get('hnsw', {}).get('ef_search', 100)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã RAG
        rag_config = self.config.get('rag', {})
        self.top_k = rag_config.get('top_k', 5)
        self.llm_model = rag_config.get('llm_model', 'llama3.1:8b')
        self.temperature = rag_config.get('temperature', 0.7)
        self.max_tokens = rag_config.get('max_tokens', 512)
        
        # Ollama
        ollama_config = rag_config.get('ollama', {})
        self.ollama_base_url = ollama_config.get('base_url', 'http://localhost:11434/v1')
        self.ollama_api_key = ollama_config.get('api_key', 'pass')
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ QDrant
        self.client = QdrantClient(host=self.host, port=self.port)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–µ—Ä
        self.embedder = DenseEmbedder(self.config['embeddings']['dense'])
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LLM –∫–ª–∏–µ–Ω—Ç (Ollama —á–µ—Ä–µ–∑ OpenAI API)
        self.llm_client = OpenAI(
            base_url=self.ollama_base_url,
            api_key=self.ollama_api_key
        )
    
    def search_relevant_chunks(self, query, top_k = None):
        """
        –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.
        
        Args:
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —á–∞–Ω–∫–∞—Ö –∏ –∏—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        """
        if top_k is None:
            top_k = self.top_k
        
        # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        model_name = self.config['embeddings']['dense']['model'].lower()
        
        if 'bge' in model_name:
            query_text = f"Represent this sentence for searching relevant passages: {query}"
        elif 'e5' in model_name:
            query_text = f"query: {query}"
        else:
            query_text = query
        
        embeddings_result = self.embedder.embed_texts([query_text])
        query_vector = embeddings_result['dense'][0].tolist()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –≤ QDrant
        results = self.client.query_points(
            collection_name=self.collection_name,
            query=query_vector,
            limit=top_k,
            with_payload=True
        ).points
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        chunks = []
        for i, result in enumerate(results):
            payload = result.payload
            chunks.append({
                'rank': i + 1,
                'score': result.score,
                'document': payload.get('document', 'unknown'),
                'chunk_id': payload.get('chunk_id', 'unknown'),
                'text': payload.get('text', ''),
                'metadata': payload.get('metadata', {})
            })
        
        return chunks
    
    def build_prompt(self, query, chunks):
        """
        –°–æ–±–∏—Ä–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM: –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ + –≤–æ–ø—Ä–æ—Å + –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã.
        
        Args:
            query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            chunks: –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
            
        Returns:
            –ì–æ—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
        """
        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏
        system_instruction = """–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞:
1. –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –∏–∑—É—á–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–∫–æ–Ω—Ç–µ–∫—Å—Ç).
2. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –æ–ø–∏—Ä–∞—è—Å—å –¢–û–õ–¨–ö–û –Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
3. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º.
4. –í –∫–æ–Ω—Ü–µ –æ—Ç–≤–µ—Ç–∞ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —É–∫–∞–∂–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏: –∏–∑ –∫–∞–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤–∑—è—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è.
5. –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏ –ø–æ–Ω—è—Ç–Ω—ã–º."""

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã –∏–∑ —á–∞–Ω–∫–æ–≤
        contexts = []
        for chunk in chunks:
            doc_name = chunk['document']
            text = chunk['text']
            metadata = chunk['metadata']
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            extra_info = []
            if 'page' in metadata:
                extra_info.append(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞: {metadata['page']}")
            if 'slide' in metadata:
                extra_info.append(f"–°–ª–∞–π–¥: {metadata['slide']}")
            if 'section' in metadata:
                extra_info.append(f"–†–∞–∑–¥–µ–ª: {metadata['section']}")
            
            extra_str = ", ".join(extra_info) if extra_info else ""
            
            context_header = f"[–î–æ–∫—É–º–µ–Ω—Ç: {doc_name}"
            if extra_str:
                context_header += f", {extra_str}"
            context_header += "]"
            
            contexts.append(f"{context_header}\n{text}")
        
        context_block = "\n\n---\n\n".join(contexts)
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        prompt = f"""{system_instruction}

=== –ö–û–ù–¢–ï–ö–°–¢ –ò–ó –î–û–ö–£–ú–ï–ù–¢–û–í ===

{context_block}

=== –í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ===

{query}

=== –û–¢–í–ï–¢ ===

"""
        
        return prompt
    
    def generate_answer(self, prompt):
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é LLM.
        
        Args:
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è LLM
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        start_time = time.time()
        
        try:
            response = self.llm_client.chat.completions.create(
                model=self.llm_model,
                messages=[{"role": "user", "content": prompt}],
                temperature=self.temperature,
                max_tokens=self.max_tokens
            )
            
            end_time = time.time()
            
            usage = response.usage
            answer_text = response.choices[0].message.content.strip()
            
            return {
                'success': True,
                'answer': answer_text,
                'model': self.llm_model,
                'tokens': {
                    'prompt': usage.prompt_tokens,
                    'completion': usage.completion_tokens,
                    'total': usage.total_tokens
                },
                'time_sec': round(end_time - start_time, 2)
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'answer': None
            }
    
    def format_citations(self, chunks):
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ü–∏—Ç–∞—Ç—ã (–∏—Å—Ç–æ—á–Ω–∏–∫–∏) –¥–ª—è –æ—Ç–≤–µ—Ç–∞.
        
        Args:
            chunks: –°–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
            
        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
        """
        citations = []
        
        for i, chunk in enumerate(chunks, 1):
            doc_name = chunk['document']
            metadata = chunk['metadata']
            text_snippet = chunk['text'][:200] + "..." if len(chunk['text']) > 200 else chunk['text']
            
            citation = f"{i}. **{doc_name}**"
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            extras = []
            if 'page' in metadata:
                extras.append(f"—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {metadata['page']}")
            if 'slide' in metadata:
                extras.append(f"—Å–ª–∞–π–¥ {metadata['slide']}")
            if 'section' in metadata:
                extras.append(f"—Ä–∞–∑–¥–µ–ª '{metadata['section']}'")
            
            if extras:
                citation += f" ({', '.join(extras)})"
            
            citation += f"\n   –§—Ä–∞–≥–º–µ–Ω—Ç: \"{text_snippet}\""
            citation += f"\n   –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {chunk['score']:.3f}"
            
            citations.append(citation)
        
        return "\n\n".join(citations)
    
    def answer_question(self, query, top_k = None):
        """
        –ü–æ–ª–Ω—ã–π RAG –ø–∞–π–ø–ª–∞–π–Ω: –ø–æ–∏—Å–∫ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è + —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞.
        
        Args:
            query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø–æ–ª–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º, —Ü–∏—Ç–∞—Ç–∞–º–∏ –∏ –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        # 1. –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
        chunks = self.search_relevant_chunks(query, top_k)
        
        if not chunks:
            return {
                'query': query,
                'answer': "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å.",
                'sources': [],
                'success': False
            }
        
        # 2. –°–±–æ—Ä–∫–∞ –ø—Ä–æ–º–ø—Ç–∞
        prompt = self.build_prompt(query, chunks)
        
        # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        llm_result = self.generate_answer(prompt)
        
        if not llm_result['success']:
            return {
                'query': query,
                'answer': f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {llm_result.get('error', 'Unknown error')}",
                'sources': [],
                'success': False
            }
        
        # 4. –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–∏—Ç–∞—Ç
        citations = self.format_citations(chunks)
        
        # 5. –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'query': query,
            'answer': llm_result['answer'],
            'sources': citations,
            'metadata': {
                'num_sources': len(chunks),
                'model': llm_result['model'],
                'tokens': llm_result['tokens'],
                'generation_time_sec': llm_result['time_sec'],
                'timestamp': datetime.now().isoformat()
            },
            'success': True
        }
        
        return result


def print_result(result):
    """–ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç RAG –ø–∞–π–ø–ª–∞–π–Ω–∞."""
    print("\n" + "="*80)
    print(f"–í–û–ü–†–û–°: {result['query']}")
    print("="*80)
    
    if not result['success']:
        print(f"\n‚ùå {result['answer']}")
        return
    
    print(f"\nüìù –û–¢–í–ï–¢:\n")
    print(result['answer'])
    
    print(f"\n\nüìö –ò–°–¢–û–ß–ù–ò–ö–ò ({result['metadata']['num_sources']}):\n")
    print(result['sources'])
    
    print("\n" + "-"*80)
    metadata = result['metadata']
    print(f"–ú–æ–¥–µ–ª—å: {metadata['model']}")
    print(f"–¢–æ–∫–µ–Ω—ã: {metadata['tokens']['prompt']} (–ø—Ä–æ–º–ø—Ç) + {metadata['tokens']['completion']} (–æ—Ç–≤–µ—Ç) = {metadata['tokens']['total']} (–≤—Å–µ–≥–æ)")
    print(f"–í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {metadata['generation_time_sec']} —Å–µ–∫")
    print("="*80 + "\n")


@click.command()
@click.argument('question', required=True)
@click.option('--top_k', '-k', type=int, default=None, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞')
@click.option('--config', '-c', default='config.yaml', help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏')
@click.option('--output', '-o', type=click.Path(), help='–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–∞–π–ª')
def main(question, top_k, config, output):
    """
    RAG Pipeline –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏ LLM.
    
    –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
    
        # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
        python scripts/rag_pipeline.py "–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?"
        
        # –° —É–∫–∞–∑–∞–Ω–∏–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        python scripts/rag_pipeline.py "–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?" --top_k 3
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        python scripts/rag_pipeline.py "–í–æ–ø—Ä–æ—Å?" --output result.json
    """
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG Pipeline
    try:
        rag = RAGPipeline(config_path=config)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ RAG Pipeline: {e}")
        sys.exit(1)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–∞
    result = rag.answer_question(question, top_k)
    print_result(result)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
    if output:
        output_path = Path(output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_path}")


if __name__ == '__main__':
    main()