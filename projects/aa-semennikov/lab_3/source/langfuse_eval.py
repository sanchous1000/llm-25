import os
import sys
import time
from pathlib import Path
from typing import List, Dict, Any
import click
from dotenv import load_dotenv
sys.path.insert(0, str(Path(__file__).parent.parent))
from langfuse import Langfuse
from source.rag_pipeline import RAGPipeline
from source.evaluation_metrics import RetrievalMetrics
from source.create_dataset import create_dataset

load_dotenv()


def get_or_create_dataset(langfuse: Langfuse, dataset_name: str, create_if_missing: bool = False):
    print(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞: {dataset_name}")
    
    try:
        dataset = langfuse.get_dataset(dataset_name)
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤, –ø–µ—Ä–µ–±–∏—Ä–∞—è items –∫–∞–∫ –∏—Ç–µ—Ä–∞—Ç–æ—Ä
        items_count = sum(1 for _ in dataset.items)
        print(f"–î–∞—Ç–∞—Å–µ—Ç '{dataset_name}' –Ω–∞–π–¥–µ–Ω ({items_count} —ç–ª–µ–º–µ–Ω—Ç–æ–≤)")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∑–∞–Ω–æ–≤–æ, —Ç–∞–∫ –∫–∞–∫ items —ç—Ç–æ –∏—Ç–µ—Ä–∞—Ç–æ—Ä –∏ —É–∂–µ –∏—Å—á–µ—Ä–ø–∞–Ω
        return langfuse.get_dataset(dataset_name)
    except Exception as e:
        if create_if_missing:
            print(f"–î–∞—Ç–∞—Å–µ—Ç '{dataset_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π...")
            created_dataset = create_dataset()
            
            # –ü–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª—É—á–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∑–∞–Ω–æ–≤–æ —á–µ—Ä–µ–∑ API
            print(f"–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —á–µ—Ä–µ–∑ API...")
            time.sleep(1)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å API
            
            dataset = langfuse.get_dataset(created_dataset.name)
            items_count = sum(1 for _ in dataset.items)
            print(f"–î–∞—Ç–∞—Å–µ—Ç '{created_dataset.name}' —Å–æ–∑–¥–∞–Ω ({items_count} —ç–ª–µ–º–µ–Ω—Ç–æ–≤)")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∑–∞–Ω–æ–≤–æ
            return langfuse.get_dataset(created_dataset.name)
        else:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ '{dataset_name}': {str(e)}")
            print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --create-dataset –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞")
            raise


def run_rag_pipeline(
    item_input: Dict[str, Any],
    rag_pipeline: RAGPipeline,
    top_k: int,
    trace
) -> tuple:
    query = item_input["question"]
    
    # 1. Retrieval - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
    chunks = rag_pipeline.search_relevant_chunks(query, top_k=top_k, trace=trace)
    retrieved_docs = [chunk['document'] for chunk in chunks]
    
    # 2. –°–±–æ—Ä–∫–∞ –ø—Ä–æ–º–ø—Ç–∞
    prompt = rag_pipeline.build_prompt(query, chunks, trace=trace)
    
    # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ LLM
    generation_result = rag_pipeline.generate_answer(prompt, trace=trace)
    answer = generation_result.get('answer', 'N/A')
    
    return answer, retrieved_docs, chunks


def run_experiment(
    experiment_name: str,
    dataset_name: str = 'dataset_2',
    config_path: str = './data/config.yaml',
    top_k: int = 5,
    create_if_missing: bool = False
):
    print("\n" + "="*80)
    print("üöÄ –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –æ—Ü–µ–Ω–∫–∏ RAG-–ø–∞–π–ø–ª–∞–π–Ω–∞")
    print("="*80)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Langfuse
    langfuse = Langfuse(
        secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
        public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
        host=os.getenv("LANGFUSE_HOST")
    )
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    dataset = get_or_create_dataset(langfuse, dataset_name, create_if_missing)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º RAG pipeline
    print(f"\nüîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG pipeline...")
    rag_pipeline = RAGPipeline(config_path=config_path)
    print(f"RAG pipeline –≥–æ—Ç–æ–≤ (model: {rag_pipeline.llm_model})")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
    print(f"\nüìä –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: {experiment_name}")
    print(f"   –î–∞—Ç–∞—Å–µ—Ç: {dataset_name}")
    print(f"   Top-K: {top_k}")
    print("-"*80)
    
    # –ü–æ–ª—É—á–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –¥–∞—Ç–∞—Å–µ—Ç–∞ (dataset.items —ç—Ç–æ –∏—Ç–µ—Ä–∞—Ç–æ—Ä/–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä)
    dataset_items = list(dataset.items)
    total_items = len(dataset_items)
    
    print(f"\nüîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ {total_items} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–∞—Ç–∞—Å–µ—Ç–∞...\n")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞
    for idx, item in enumerate(dataset_items, 1):
        query = item.input["question"]
        expected_docs = set(item.expected_output["relevant_documents"])
        
        print(f"[{idx}/{total_items}] üîç {query[:60]}...")
        
        # –°–æ–∑–¥–∞–µ–º run –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
        with item.run(
            run_name=experiment_name,
            run_description="–û—Ü–µ–Ω–∫–∞ RAG –ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —á–∞–Ω–∫–æ–≤",
        ) as root_span:
            try:
                # –í—ã–ø–æ–ª–Ω—è–µ–º RAG pipeline
                answer, retrieved_docs, chunks = run_rag_pipeline(
                    item.input,
                    rag_pipeline,
                    top_k,
                    root_span
                )
                
                # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
                precision_at_k = RetrievalMetrics.precision_at_k(
                    retrieved=retrieved_docs,
                    relevant=expected_docs,
                    k=top_k
                )
                
                recall_at_k = RetrievalMetrics.recall_at_k(
                    retrieved=retrieved_docs,
                    relevant=expected_docs,
                    k=top_k
                )
                
                mrr = RetrievalMetrics.mrr(
                    retrieved=retrieved_docs,
                    relevant=expected_docs
                )
                
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞–∫ scores —á–µ—Ä–µ–∑ root_span.score_trace()
                root_span.score_trace(
                    name=f"precision@{top_k}",
                    value=precision_at_k,
                    comment=f"Precision@{top_k} for retrieval"
                )
                
                root_span.score_trace(
                    name=f"recall@{top_k}",
                    value=recall_at_k,
                    comment=f"Recall@{top_k} for retrieval"
                )
                
                root_span.score_trace(
                    name="mrr",
                    value=mrr,
                    comment="Mean Reciprocal Rank"
                )
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π trace —Å input –∏ output
                langfuse.update_current_trace(
                    input=item.input,
                    output={
                        "answer": answer,
                        "retrieved_documents": retrieved_docs,
                        "num_chunks": len(chunks)
                    }
                )
                
                print(f"    Precision@{top_k}: {precision_at_k:.3f} | Recall@{top_k}: {recall_at_k:.3f} | MRR: {mrr:.3f}")
                
            except Exception as e:
                print(f"    –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {str(e)}")
                # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –≤ trace
                root_span.update(
                    level="ERROR",
                    status_message=str(e)
                )
    
    print(f"\n–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {total_items}")
    print("\n" + "="*80)
    
    # Flush –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –≤ Langfuse
    langfuse.flush()


@click.command()
@click.option('--experiment-name', '-e', required=True, help='–ù–∞–∑–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞')
@click.option('--dataset-name', '-d', default='dataset_2', help='–ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ Langfuse (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: dataset_2)')
@click.option('--config', '-c', default='./data/config.yaml', help='–ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ RAG')
@click.option('--top-k', '-k', type=int, default=5, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è retrieval')
@click.option('--create-dataset', is_flag=True, default=False, help='–°–æ–∑–¥–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç, –µ—Å–ª–∏ –æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω')
def main(experiment_name, dataset_name, config, top_k, create_dataset):
    run_experiment(
        experiment_name=experiment_name,
        dataset_name=dataset_name,
        config_path=config,
        top_k=top_k,
        create_if_missing=create_dataset
    )


if __name__ == "__main__":
    main()